---
title: "NHL Goalie Starter Model"
author: "Sasank Vishnubhatla"
date: "October 14, 2018"
runtime: shiny
---

This model is a very simple neural network model. It is currently based on two years of data (from [Corsica](http://corsica.hockey/goalie-stats/)). The data being used is:

- Shots Against (SA)
- Goals Agasint (GA)
- Save Percentage (Sv)
- Low Danger Shots Against (LdSA)
- Low Danger Goals Against (LdGA)
- Low Danger Save Percentage (LdSv)
- Mid Danger Shots Against (MdSA)
- Mid Danger Goals Against (MdGA)
- Mid Danger Save Percentage (MdSv)
- High Danger Shots Against (HdSA)
- High Danger Goals Against (HdGA)
- High Danger Save Percentage (HdSv)

## Visualizing Data

Before we start with building the neural network, we must first visualize some the important statistics we are using. So, let's first visualize danger shots against vs danger shot percentage.

```{r}
require(ggplot2)
```

So now, let's read our data in. Make sure you have the data from the repository. Repository can be found [here](https://github.com/sv4u/nhl-goalie-starter-model).

Now, with the data stored in the `data` folder, we can start importing it.

```{r}
data01 <- read.csv("data/goalie_stats_20172018.csv")
data02 <- read.csv("data/goalie_stats_20162017.csv")
current <- read.csv("data/goalie_stats_20182019.csv")
old <- read.csv("data/goalie_stats_20152016.csv")
```

Now that we have all data imported, we can create data frames for our graphs.

First, low danger shots:

```{r}
lowDanger <-
	data.frame(
		name = data01["Player"][[1]],
		ldsa = data01["LDSA"][[1]],
		ldsv = data01["LDSv."][[1]],
		ldga = data01["LDGA"][[1]]
	)
```

Now, using `ggplot`, we can create a plot with a varying point size.

```{r}
ldGraph <- ggplot(lowDanger, aes(x = ldsa, y = ldsv)) +
	geom_point(alpha = 0.6, aes(size = ldga), show.legend = T) +
	theme_minimal() +
	ggtitle("Low Danger Shots Against vs Save Percentage") +
	labs(x = "Low Danger Shots Against",
		 y = "Low Danger Save Percentage",
		 size = "Low Danger Goals Against")
```

So, it will look like this:

```{r}
print(ldGraph)
```

Now, to create the same graph for mid and high danger graphs.

```{r}
midDanger <-
	data.frame(
		name = data01["Player"][[1]],
		mdsa = data01["MDSA"][[1]],
		mdsv = data01["MDSv."][[1]],
		mdga = data01["MDGA"][[1]]
	)

mdGraph <- ggplot(midDanger, aes(x = mdsa, y = mdsv)) +
	geom_point(alpha = 0.6, aes(size = mdga), show.legend = T) +
	theme_minimal() +
	ggtitle("Mid Danger Shots Against vs Save Percentage") +
	labs(x = "Mid Danger Shots Against",
		 y = "Mid Danger Save Percentage",
		 size = "Mid Danger Goals Against")

print(mdGraph)

highDanger <-
	data.frame(
		name = data01["Player"][[1]],
		hdsa = data01["HDSA"][[1]],
		hdsv = data01["HDSv."][[1]],
		hdga = data01["HDGA"][[1]]
	)

hdGraph <- ggplot(highDanger, aes(x = hdsa, y = hdsv)) +
	geom_point(alpha = 0.6, aes(size = hdga), show.legend = T) +
	theme_minimal() +
	ggtitle("High Danger Shots Against vs Save Percentage") +
	labs(x = "High Danger Shots Against",
		 y = "High Danger Save Percentage",
		 size = "High Danger Goals Against")

print(hdGraph)
```

## Neural Network

### Build the Neural Network

To build the neural network, we will use the `neuralnet` package.

```{r}
require(neuralnet)
```

Now, we must classify our data in order to train it. So, let's start with the 2017-2018 data.

```{r}
learningStarter01 <- list(rep(0, length(data01$Player)))[[1]]
learningStarter01[13:18] = 1
learningStarter01[24:27] = 1
learningStarter01[31] = 1
learningStarter01[33] = 1
learningStarter01[35] = 1
learningStarter01[37:39] = 1
learningStarter01[44:47] = 1
learningStarter01[57:60] = 1
learningStarter01[62] = 1
learningStarter01[64] = 1
learningStarter01[66] = 1
learningStarter01[70:71] = 1
learningStarter01[73] = 1
learningStarter01[75:76] = 1
learningStarter01[80] = 1
```

The code above sets certain goalies as starters and others as backups. If the value of `learningStarter01[i]` is `1`, then the goalie is a starter. Otherwise, thte goalie is a backup.

Now, we can build a dataframe to contain all possible data for our neural network.

```{r}
learning01 <- data.frame(
	name = data01["Player"][[1]],
	starter = learningStarter01,
	sa = data01["SA"][[1]],
	ga = data01["GA"][[1]],
	sv = data01["Sv."][[1]],
	ldsa = data01["LDSA"][[1]],
	ldga = data01["LDGA"][[1]],
	ldsv = data01["LDSv."][[1]],
	mdsa = data01["MDSA"][[1]],
	mdga = data01["MDGA"][[1]],
	mdsv = data01["MDSv."][[1]],
	hdsa = data01["HDSA"][[1]],
	hdga = data01["HDGA"][[1]],
	hdsv = data01["HDSv."][[1]]
)

learning01 <- learning01[complete.cases(learning01),]
```

The final line removes goalies who have incomplete data.

Now that we have our data in an organized manner, we can run our neural network function on it.

```{r}
features <- names(learning01[3:14])
form <- paste(features, collapse = " + ")
form <- paste('learning01$starter ~', form)
form <- as.formula(form)

nn01 <-
	neuralnet(form,
			  learning01[3:14],
			  hidden = c(10, 10, 10),
			  linear.output = FALSE)
```

Now with the network made, let's classify the 2016-2017 data to create a secondary model.

```{r}
learningStarter02 = list(rep(0, length(data02$Player)))[[1]]
learningStarter02[6] = 1
learningStarter02[12] = 1
learningStarter02[14:20] = 1
learningStarter02[25:28] = 1
learningStarter02[32] = 1
learningStarter02[36:37] = 1
learningStarter02[40:41] = 1
learningStarter02[49] = 1
learningStarter02[58] = 1
learningStarter02[66] = 1
learningStarter02[69:70] = 1
learningStarter02[75] = 1
learningStarter02[77:79] = 1
learningStarter02[84:86] = 1
learningStarter02[89] = 1
learningStarter02[91:92] = 1
learningStarter02[94] = 1

learning02 <- data.frame(
	name = data02["Player"][[1]],
	starter = learningStarter02,
	sa = data02["SA"][[1]],
	ga = data02["GA"][[1]],
	sv = data02["Sv."][[1]],
	ldsa = data02["LDSA"][[1]],
	ldga = data02["LDGA"][[1]],
	ldsv = data02["LDSv."][[1]],
	mdsa = data02["MDSA"][[1]],
	mdga = data02["MDGA"][[1]],
	mdsv = data02["MDSv."][[1]],
	hdsa = data02["HDSA"][[1]],
	hdga = data02["HDGA"][[1]],
	hdsv = data02["HDSv."][[1]]
)

learning02 <- learning02[complete.cases(learning02),]
```

Now, let's combine `learning01` with `learning02` and create a new neural network model based on 2 years of data.

```{r}
learning03 = rbind(learning01, learning02)

features <- names(learning03[3:14])
form <- paste(features, collapse = " + ")
form <- paste('learning03$starter ~', form)
form <- as.formula(form)

nn02 <-
	neuralnet(form,
			  learning03[3:14],
			  hidden = c(10, 10, 10),
			  linear.output = FALSE)
```

Now with our two neural networks (`nn01`, `nn02`), we can try and determine if teams are using the right goalie as a starter.

## Determining if Matt Murray is a starter

Let's start with looking at the Pittsburgh Penguins. Currently, their starting goalie is Matt Murray. However, Murray's stats as of October 25 do not look like the numbers of a two-time Stanley Cup winner: 3-1 (W-L), 3.95 goals against average, and 89.3% save percentage. Using our neural network, let's see if he should be the starter:

```{r}
murrayRaw <- filter(current, current$Player == "MATT.MURRAY")
murrayFrame <- data.frame(
	sa = murrayRaw["SA"][[1]],
	ga = murrayRaw["GA"][[1]],
	sv = murrayRaw["Sv."][[1]],
	ldsa = murrayRaw["LDSA"][[1]],
	ldga = murrayRaw["LDGA"][[1]],
	ldsv = murrayRaw["LDSv."][[1]],
	mdsa = murrayRaw["MDSA"][[1]],
	mdga = murrayRaw["MDGA"][[1]],
	mdsv = murrayRaw["MDSv."][[1]],
	hdsa = murrayRaw["HDSA"][[1]],
	hdga = murrayRaw["HDGA"][[1]],
	hdsv = murrayRaw["HDSv."][[1]]
)

murrayPrediction01 <- compute(nn01, murrayFrame)
murrayPrediction02 <- compute(nn02, murrayFrame)
```

Now with the predictions, we can see if Matt Murray has been good enough to be a starter this year. Murray seems to have been at the level of a ---.

## Difference between established starters and established backups

I personally think it is valuable  to now consider Murray's numbers to an established starter and to an established backup. For the established starter, I've chosen Tuuka Rask. For the established backup, I believe Mike Condon is an established backup.

```{r}
raskRaw <- filter(current, current$Player == "TUUKKA.RASK")
raskFrame <- data.frame(
	sa = raskRaw["SA"][[1]],
	ga = raskRaw["GA"][[1]],
	sv = raskRaw["Sv."][[1]],
	ldsa = raskRaw["LDSA"][[1]],
	ldga = raskRaw["LDGA"][[1]],
	ldsv = raskRaw["LDSv."][[1]],
	mdsa = raskRaw["MDSA"][[1]],
	mdga = raskRaw["MDGA"][[1]],
	mdsv = raskRaw["MDSv."][[1]],
	hdsa = raskRaw["HDSA"][[1]],
	hdga = raskRaw["HDGA"][[1]],
	hdsv = raskRaw["HDSv."][[1]]
)

raskPrediction01 <- compute(nn01, raskFrame)
raskPrediction02 <- compute(nn02, raskFrame)
```

Now for Mike Condon.

```{r}
condonRaw <- filter(current, current$Player == "MIKE.CONDON")
condonFrame <- data.frame(
	sa = condonRaw["SA"][[1]],
	ga = condonRaw["GA"][[1]],
	sv = condonRaw["Sv."][[1]],
	ldsa = condonRaw["LDSA"][[1]],
	ldga = condonRaw["LDGA"][[1]],
	ldsv = condonRaw["LDSv."][[1]],
	mdsa = condonRaw["MDSA"][[1]],
	mdga = condonRaw["MDGA"][[1]],
	mdsv = condonRaw["MDSv."][[1]],
	hdsa = condonRaw["HDSA"][[1]],
	hdga = condonRaw["HDGA"][[1]],
	hdsv = condonRaw["HDSv."][[1]]
)

condonPrediction01 <- compute(nn01, condonFrame)
condonPrediction02 <- compute(nn02, condonFrame)
```

Now the prediction for Rask leaves him at a ---- percent chance, compared to Condon's of ---- percent.